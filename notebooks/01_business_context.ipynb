{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Sales Analytics: Business Context\n",
    "\n",
    "## Welcome to Your Role as a Senior Data Scientist at Amazon!\n",
    "\n",
    "In this notebook, you'll learn about the business context and your role in Amazon's sales analytics team. This is the foundation for understanding how machine learning models add value to real business operations.\n",
    "\n",
    "### Learning Objectives\n",
    "- Understand Amazon's sales process and key metrics\n",
    "- Learn about business KPIs and stakeholder communication\n",
    "- Generate and explore sample sales data\n",
    "- Perform initial exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Business Context: Amazon Sales Analytics\n",
    "\n",
    "### Your Role\n",
    "As a Senior Data Scientist in Amazon's sales analytics team, you are responsible for:\n",
    "\n",
    "- **Revenue Forecasting**: Predicting daily, weekly, and monthly sales\n",
    "- **Demand Planning**: Optimizing inventory levels across warehouses\n",
    "- **Marketing ROI**: Measuring the effectiveness of marketing campaigns\n",
    "- **Pricing Strategy**: Understanding price elasticity and optimal pricing\n",
    "- **Performance Monitoring**: Detecting when models need retraining\n",
    "\n",
    "### Key Business Metrics\n",
    "- **Revenue**: Total sales value and growth trends\n",
    "- **Conversion Rate**: Percentage of visitors who make purchases\n",
    "- **Average Order Value (AOV)**: Revenue per transaction\n",
    "- **Customer Lifetime Value (CLV)**: Long-term customer value\n",
    "- **Marketing ROI**: Return on marketing investment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sample Data Generation\n",
    "\n",
    "Let's generate realistic Amazon sales data to work with throughout this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate 1000 days of sales data\n",
    "n_days = 1000\n",
    "dates = pd.date_range(start='2021-01-01', periods=n_days, freq='D')\n",
    "\n",
    "# Create realistic sales features\n",
    "data = {\n",
    "    'date': dates,\n",
    "    'marketing_spend': np.random.uniform(10000, 100000, n_days),\n",
    "    'website_traffic': np.random.uniform(50000, 200000, n_days),\n",
    "    'avg_product_price': np.random.uniform(20, 200, n_days),\n",
    "    'customer_reviews': np.random.uniform(3.5, 5.0, n_days),\n",
    "    'inventory_level': np.random.uniform(0.3, 1.0, n_days),\n",
    "    'competitor_price_ratio': np.random.uniform(0.8, 1.2, n_days)\n",
    "}\n",
    "\n",
    "# Add seasonal patterns\n",
    "day_of_year = np.array([d.timetuple().tm_yday for d in dates])\n",
    "seasonal_factor = np.sin(2 * np.pi * day_of_year / 365) * 0.3\n",
    "\n",
    "# Add weekly patterns (higher sales on weekends)\n",
    "weekday = np.array([d.weekday() for d in dates])\n",
    "weekend_boost = np.where(weekday >= 5, 0.2, 0)\n",
    "\n",
    "# Add holiday effects\n",
    "holiday_dates = ['2021-11-26', '2021-12-25', '2022-01-01', '2022-07-04', '2022-11-25', '2022-12-25']\n",
    "holiday_boost = np.zeros(n_days)\n",
    "for holiday in holiday_dates:\n",
    "    holiday_date = pd.to_datetime(holiday)\n",
    "    if holiday_date in dates:\n",
    "        idx = dates.get_loc(holiday_date)\n",
    "        holiday_boost[max(0, idx-2):min(n_days, idx+3)] = 0.5\n",
    "\n",
    "# Generate revenue with realistic relationships\n",
    "revenue = (\n",
    "    50000 +                                    # Base revenue\n",
    "    0.8 * data['marketing_spend'] +            # Marketing impact\n",
    "    0.3 * data['website_traffic'] +            # Traffic impact\n",
    "    100 * data['avg_product_price'] +          # Price impact\n",
    "    20000 * data['customer_reviews'] +         # Reviews impact\n",
    "    15000 * data['inventory_level'] +          # Inventory impact\n",
    "    -10000 * data['competitor_price_ratio'] +  # Competition impact\n",
    "    30000 * seasonal_factor +                  # Seasonal impact\n",
    "    20000 * weekend_boost +                    # Weekend boost\n",
    "    40000 * holiday_boost +                    # Holiday boost\n",
    "    np.random.normal(0, 8000, n_days)         # Random noise\n",
    ")\n",
    "\n",
    "# Create DataFrame\n",
    "data['revenue'] = revenue\n",
    "sales_df = pd.DataFrame(data)\n",
    "\n",
    "print(f\"Generated {len(sales_df)} days of sales data\")\n",
    "print(f\"Date range: {sales_df['date'].min()} to {sales_df['date'].max()}\")\n",
    "print(f\"Revenue range: ${sales_df['revenue'].min():,.0f} to ${sales_df['revenue'].max():,.0f}\")\n",
    "print(f\"Average daily revenue: ${sales_df['revenue'].mean():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis\n",
    "\n",
    "Let's explore our sales data to understand patterns and relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"Dataset Shape:\", sales_df.shape)\n",
    "print(\"\\nColumn Information:\")\n",
    "print(sales_df.info())\n",
    "print(\"\\nFirst few rows:\")\n",
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"Statistical Summary:\")\n",
    "sales_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revenue trends over time\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Revenue trend\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(sales_df['date'], sales_df['revenue'], alpha=0.7)\n",
    "plt.title('Daily Revenue Trend')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Revenue ($)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Monthly revenue\n",
    "monthly_revenue = sales_df.set_index('date').resample('M')['revenue'].sum()\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(monthly_revenue.index, monthly_revenue.values, marker='o')\n",
    "plt.title('Monthly Revenue')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Revenue ($)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Revenue distribution\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.hist(sales_df['revenue'], bins=50, alpha=0.7)\n",
    "plt.title('Revenue Distribution')\n",
    "plt.xlabel('Revenue ($)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Box plot by day of week\n",
    "sales_df['day_of_week'] = sales_df['date'].dt.day_name()\n",
    "plt.subplot(2, 2, 4)\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "sns.boxplot(data=sales_df, x='day_of_week', y='revenue', order=day_order)\n",
    "plt.title('Revenue by Day of Week')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Correlation Analysis\n",
    "\n",
    "Let's examine relationships between different variables and revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "correlation_cols = ['marketing_spend', 'website_traffic', 'avg_product_price', \n",
    "                   'customer_reviews', 'inventory_level', 'competitor_price_ratio', 'revenue']\n",
    "correlation_matrix = sales_df[correlation_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5)\n",
    "plt.title('Correlation Matrix: Sales Variables')\n",
    "plt.show()\n",
    "\n",
    "# Print correlation with revenue\n",
    "print(\"Correlation with Revenue:\")\n",
    "revenue_corr = correlation_matrix['revenue'].drop('revenue').sort_values(key=abs, ascending=False)\n",
    "for var, corr in revenue_corr.items():\n",
    "    print(f\"{var:<25}: {corr:>6.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots for key relationships\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "key_vars = ['marketing_spend', 'website_traffic', 'avg_product_price', \n",
    "           'customer_reviews', 'inventory_level', 'competitor_price_ratio']\n",
    "\n",
    "for i, var in enumerate(key_vars):\n",
    "    axes[i].scatter(sales_df[var], sales_df['revenue'], alpha=0.5)\n",
    "    axes[i].set_xlabel(var.replace('_', ' ').title())\n",
    "    axes[i].set_ylabel('Revenue ($)')\n",
    "    axes[i].set_title(f'Revenue vs {var.replace(\"_\", \" \").title()}')\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(sales_df[var], sales_df['revenue'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    axes[i].plot(sales_df[var], p(sales_df[var]), \"r--\", alpha=0.8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Business Insights\n",
    "\n",
    "Based on our exploratory analysis, let's identify key business insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business insights\n",
    "print(\"=== BUSINESS INSIGHTS ===\")\n",
    "print(\"\\n1. Revenue Patterns:\")\n",
    "print(f\"   • Average daily revenue: ${sales_df['revenue'].mean():,.0f}\")\n",
    "print(f\"   • Revenue volatility (std): ${sales_df['revenue'].std():,.0f}\")\n",
    "print(f\"   • Peak revenue day: {sales_df.loc[sales_df['revenue'].idxmax(), 'date'].strftime('%Y-%m-%d')}\")\n",
    "print(f\"   • Peak revenue amount: ${sales_df['revenue'].max():,.0f}\")\n",
    "\n",
    "print(\"\\n2. Key Drivers (Correlation with Revenue):\")\n",
    "for var, corr in revenue_corr.head(3).items():\n",
    "    print(f\"   • {var.replace('_', ' ').title()}: {corr:.3f}\")\n",
    "\n",
    "print(\"\\n3. Seasonal Patterns:\")\n",
    "monthly_avg = sales_df.set_index('date').resample('M')['revenue'].mean()\n",
    "peak_month = monthly_avg.idxmax().strftime('%B %Y')\n",
    "low_month = monthly_avg.idxmin().strftime('%B %Y')\n",
    "print(f\"   • Peak month: {peak_month} (${monthly_avg.max():,.0f} avg)\")\n",
    "print(f\"   • Low month: {low_month} (${monthly_avg.min():,.0f} avg)\")\n",
    "\n",
    "print(\"\\n4. Day-of-Week Effects:\")\n",
    "dow_avg = sales_df.groupby('day_of_week')['revenue'].mean()\n",
    "dow_avg = dow_avg.reindex(day_order)\n",
    "best_day = dow_avg.idxmax()\n",
    "worst_day = dow_avg.idxmin()\n",
    "print(f\"   • Best performing day: {best_day} (${dow_avg[best_day]:,.0f} avg)\")\n",
    "print(f\"   • Worst performing day: {worst_day} (${dow_avg[worst_day]:,.0f} avg)\")\n",
    "\n",
    "print(\"\\n5. Marketing Efficiency:\")\n",
    "marketing_roi = sales_df['revenue'] / sales_df['marketing_spend']\n",
    "print(f\"   • Average marketing ROI: {marketing_roi.mean():.2f}x\")\n",
    "print(f\"   • Best marketing ROI: {marketing_roi.max():.2f}x\")\n",
    "print(f\"   • Marketing spend range: ${sales_df['marketing_spend'].min():,.0f} - ${sales_df['marketing_spend'].max():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Quality Assessment\n",
    "\n",
    "Let's check for data quality issues that might affect our machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality checks\n",
    "print(\"=== DATA QUALITY ASSESSMENT ===\")\n",
    "\n",
    "print(\"\\n1. Missing Values:\")\n",
    "missing_values = sales_df.isnull().sum()\n",
    "if missing_values.sum() == 0:\n",
    "    print(\"   ✓ No missing values found\")\n",
    "else:\n",
    "    print(missing_values[missing_values > 0])\n",
    "\n",
    "print(\"\\n2. Duplicate Records:\")\n",
    "duplicates = sales_df.duplicated().sum()\n",
    "if duplicates == 0:\n",
    "    print(\"   ✓ No duplicate records found\")\n",
    "else:\n",
    "    print(f\"   ⚠ {duplicates} duplicate records found\")\n",
    "\n",
    "print(\"\\n3. Outliers Detection (using IQR method):\")\n",
    "numeric_cols = ['marketing_spend', 'website_traffic', 'avg_product_price', 'revenue']\n",
    "for col in numeric_cols:\n",
    "    Q1 = sales_df[col].quantile(0.25)\n",
    "    Q3 = sales_df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = ((sales_df[col] < lower_bound) | (sales_df[col] > upper_bound)).sum()\n",
    "    print(f\"   • {col}: {outliers} outliers ({outliers/len(sales_df)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n4. Data Types:\")\n",
    "print(sales_df.dtypes)\n",
    "\n",
    "print(\"\\n5. Value Ranges:\")\n",
    "for col in numeric_cols:\n",
    "    print(f\"   • {col}: {sales_df[col].min():.0f} to {sales_df[col].max():.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Next Steps\n",
    "\n",
    "### Key Takeaways from Business Context Analysis:\n",
    "\n",
    "1. **Data Quality**: Our dataset is clean with no missing values or duplicates\n",
    "2. **Strong Relationships**: Marketing spend and website traffic show strong positive correlation with revenue\n",
    "3. **Seasonal Patterns**: Clear seasonal and day-of-week patterns in sales\n",
    "4. **Business Impact**: Understanding these patterns can help optimize marketing spend and inventory\n",
    "\n",
    "### Next Steps:\n",
    "1. **Notebook 2**: Learn linear regression fundamentals\n",
    "2. **Notebook 3**: Build multiple linear regression models\n",
    "3. **Notebook 4**: Evaluate model performance\n",
    "4. **Notebook 5**: Deploy models to production\n",
    "\n",
    "### Business Questions to Answer:\n",
    "- How much revenue can we expect from a given marketing spend?\n",
    "- What is the optimal marketing budget allocation?\n",
    "- How do seasonal factors affect our sales forecasts?\n",
    "- Which variables are most important for predicting revenue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataset for use in subsequent notebooks\n",
    "sales_df.to_csv('../data/amazon_sales_data.csv', index=False)\n",
    "print(\"Dataset saved to '../data/amazon_sales_data.csv'\")\n",
    "print(\"\\nReady to move to the next notebook: 02_linear_regression_fundamentals.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}